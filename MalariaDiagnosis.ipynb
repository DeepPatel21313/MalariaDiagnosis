{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepPatel21313/MalariaDiagnosis/blob/main/MalariaDiagnosis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TronmI31hpmB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, InputLayer, BatchNormalization\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa1fc-fxtHQV"
      },
      "source": [
        "# Data Preparation\n",
        "# Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m521F6_h1PY"
      },
      "outputs": [],
      "source": [
        "dataset, dataset_info = tfds.load('malaria', with_info=True, as_supervised=True, shuffle_files=True, split=['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CV0ewgertxF"
      },
      "outputs": [],
      "source": [
        "def splits(dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO):\n",
        "  DATASET_SIZE = len(dataset)\n",
        "  train_dataset = dataset.take(int(TRAIN_RATIO*DATASET_SIZE))\n",
        "\n",
        "  val_test_dataset = dataset.skip(int(TRAIN_RATIO*DATASET_SIZE))\n",
        "  val_dataset = val_test_dataset.take(int(VAL_RATIO*DATASET_SIZE))\n",
        "\n",
        "  test_dataset = val_test_dataset.skip(int(VAL_RATIO*DATASET_SIZE))\n",
        "  return train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GY9KsKZklrS"
      },
      "outputs": [],
      "source": [
        "TRAIN_RATIO = 0.8\n",
        "VAL_RATIO = 0.1\n",
        "TEST_RATIO = 0.1\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = splits(dataset[0], TRAIN_RATIO, VAL_RATIO, TEST_RATIO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYk1tQnHu3Hs"
      },
      "source": [
        "# Dataset Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn6RVco-jHa3"
      },
      "outputs": [],
      "source": [
        "for i, (image, label) in enumerate(train_dataset.take(16)):\n",
        "  ax = plt.subplot(4, 4, i + 1)\n",
        "  plt.imshow(image)\n",
        "  plt.title(dataset_info.features['label'].int2str(label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzL6gd8bv3UF"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWNbPfdvC5yF"
      },
      "outputs": [],
      "source": [
        "IM_SIZE = 224\n",
        "def resize_rescale(image, label):\n",
        "  return tf.image.resize(image, (IM_SIZE, IM_SIZE))/255.0, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVsjLD0YvNtU"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(resize_rescale)\n",
        "val_dataset = val_dataset.map(resize_rescale)\n",
        "test_dataset = test_dataset.map(resize_rescale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xzf17b-0DSfk"
      },
      "outputs": [],
      "source": [
        "for image, label in train_dataset.take(1):\n",
        "  print(image, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQv7CxJ5DbsM"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf2d5rdDbFD5"
      },
      "outputs": [],
      "source": [
        "val_dataset = val_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAyv1JNZk0se"
      },
      "outputs": [],
      "source": [
        "val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY5kOavZk2hC"
      },
      "outputs": [],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjxctwZSEvwL"
      },
      "outputs": [],
      "source": [
        "lenet_model = tf.keras.Sequential([InputLayer(input_shape=(IM_SIZE, IM_SIZE, 3)),\n",
        "\n",
        "                             Conv2D(filters=6, kernel_size=3, strides=1, padding='valid', activation='relu'),\n",
        "                             BatchNormalization(),\n",
        "                             MaxPool2D(pool_size=2, strides=2),\n",
        "\n",
        "                             Conv2D(filters=16, kernel_size=3, strides=1, padding='valid', activation='relu'),\n",
        "                             BatchNormalization(),\n",
        "                             MaxPool2D(pool_size=2, strides=2),\n",
        "\n",
        "                             Flatten(),\n",
        "\n",
        "                             Dense(100, activation='relu'),\n",
        "                             BatchNormalization(),\n",
        "                             Dense(10, activation='relu'),\n",
        "                             BatchNormalization(),\n",
        "                             Dense(1, activation='sigmoid'),\n",
        "                             ])\n",
        "lenet_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okSFvoinVmPy"
      },
      "outputs": [],
      "source": [
        "# y_true = [0, 1, 0, 0]\n",
        "# y_pred = [0.6, 0.00051, 0.94, 0.00001]\n",
        "# bce = tf.keras.losses.BinaryCrossentropy()\n",
        "# bce(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQs15ZkAXi5V"
      },
      "outputs": [],
      "source": [
        "lenet_model.compile(optimizer = Adam(learning_rate = 0.01),\n",
        "              loss = BinaryCrossentropy(),\n",
        "              metrics = 'accuracy'\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOpvJwSnY3xB"
      },
      "outputs": [],
      "source": [
        "history = lenet_model.fit(train_dataset, validation_data=val_dataset, epochs = 20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eylD8sadZDDE"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJdYPUMTfLWd"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_accuracy', 'val_accuracy'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfguHyuZp_Hu"
      },
      "source": [
        "# Model Evaluation and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H7F3Oxixf0E"
      },
      "outputs": [],
      "source": [
        "test_dataset = test_dataset.batch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmtW7k8rxojm"
      },
      "outputs": [],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZvEY22lp-6n"
      },
      "outputs": [],
      "source": [
        "lenet_model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jare7Vbr0qKX"
      },
      "outputs": [],
      "source": [
        "def parasite_or_not(x):\n",
        "  if(x<0.5):\n",
        "    return str('P')\n",
        "  else:\n",
        "    return str('U')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKbK4qqVqFn8"
      },
      "outputs": [],
      "source": [
        "parasite_or_not(lenet_model.predict(test_dataset.take(1))[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9FlK2ig06xI"
      },
      "outputs": [],
      "source": [
        "for i, (image,label) in enumerate(test_dataset.take(9)):\n",
        "  ax = plt.subplot(3, 3, i+1)\n",
        "  plt.imshow(image[0])\n",
        "  plt.title(str(parasite_or_not(label.numpy()[0])) + \":\" + str(parasite_or_not(lenet_model.predict(image)[0][0])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i6dU_k7fkXMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-fkhcH6_oRc"
      },
      "source": [
        "# Saving and loading in colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IubIOi_Q8-Rp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnre4VJ-7mqW"
      },
      "outputs": [],
      "source": [
        "# drive.mount('/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOakvGs58027"
      },
      "outputs": [],
      "source": [
        "lenet_model.save('/drive/MyDrive/lenet_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df-HBd4h9pFP"
      },
      "outputs": [],
      "source": [
        "loaded_model = load_model('/drive/MyDrive/lenet_model.h5')\n",
        "loaded_model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzIeIilc_64g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "mount_file_id": "1zh7EpqdFmDJW1ocI2cewGDFegkMWFDa3",
      "authorship_tag": "ABX9TyOyAAQCcKuapSX3PeZdV2Ot",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}